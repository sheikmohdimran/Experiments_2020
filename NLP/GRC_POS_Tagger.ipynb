{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRC_POS_Tagger.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheikmohdimran/Experiments_2020/blob/master/NLP/GRC_POS_Tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqm7Ju1Z-2jY",
        "colab_type": "text"
      },
      "source": [
        "#POS Tag Prediction\n",
        "Since the input data was provided without tags, we will be using a freely available industry dataset, to train a POS tagger. The best model from the training will be used for predict tags for random text from the input file.\n",
        "\n",
        "If this process has to be extended to train the provided dataset, the input sentences have to formatted to include the POS tags and in the existing format to be fed into the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1HRvDvY-2Tk",
        "colab_type": "text"
      },
      "source": [
        "For this solution I use Flair, a popular NLP library which has given outstanding results in various benchmarks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJbaM-3cPGh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "53f61557-8240-450e-f184-95fbefc5f2e4"
      },
      "source": [
        "!pip -q install flair==0.4.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 184kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 778kB 40.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 798kB 47.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 44.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 348kB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 42.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 48.2MB/s \n",
            "\u001b[?25h  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4gNyOD99vzd",
        "colab_type": "text"
      },
      "source": [
        "##Use Pre-trained Model for POS prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YpUFhDpPHJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "29fee206-e84e-44cf-fc2d-77d2b8d096ae"
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "\n",
        "tagger = SequenceTagger.load('pos')\n",
        "sentence = Sentence('type iv securities. a national bank may purchase and sell type iv securities for its own account. the amount of the type iv securities that a bank may purchase and sell is not limited to a specified percentage of the banks capital and surplus.')\n",
        "tagger.predict(sentence)\n",
        "print(sentence.to_tagged_string())\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:16:34,206 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/POS-ontonotes--h256-l1-b32-p3-0.5-%2Bglove%2Bnews-forward%2Bnews-backward-normal-locked0.5-word0.05--v0.4_0/en-pos-ontonotes-v0.4.pt not found in cache, downloading to /tmp/tmppopft3jb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 432218302/432218302 [00:47<00:00, 9166621.05B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:17:22,534 copying /tmp/tmppopft3jb to cache at /root/.flair/models/en-pos-ontonotes-v0.4.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:17:24,541 removing temp file /tmp/tmppopft3jb\n",
            "2020-01-07 12:17:24,612 loading file /root/.flair/models/en-pos-ontonotes-v0.4.pt\n",
            "type <NOUN> iv <NOUN> securities. <NOUN> a <DET> national <ADJ> bank <NOUN> may <AUX> purchase <VERB> and <CCONJ> sell <VERB> type <NOUN> iv <NOUN> securities <NOUN> for <ADP> its <PRON> own <ADJ> account. <NOUN> the <DET> amount <NOUN> of <ADP> the <DET> type <NOUN> iv <NOUN> securities <NOUN> that <PRON> a <DET> bank <NOUN> may <AUX> purchase <VERB> and <CCONJ> sell <VERB> is <VERB> not <ADV> limited <VERB> to <ADP> a <DET> specified <VERB> percentage <NOUN> of <ADP> the <DET> banks <NOUN> capital <NOUN> and <CCONJ> surplus. <NOUN>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYrpGanw92JS",
        "colab_type": "text"
      },
      "source": [
        "##Train Custom Neural Net for POS prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FczXlkLPR0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.embeddings import TokenEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
        "from typing import List\n",
        "from flair.datasets import WIKINER_ENGLISH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV6H0OwDR2dJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8ac7a87b-e513-4cd8-ecf4-dd34a8fccfc3"
      },
      "source": [
        "corpus: Corpus = WIKINER_ENGLISH()\n",
        "print(corpus)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:38:41,620 Reading data from /root/.flair/datasets/wikiner_english\n",
            "2020-01-07 09:38:41,622 Train: /root/.flair/datasets/wikiner_english/aij-wikiner-en-wp3.train\n",
            "2020-01-07 09:38:41,624 Dev: None\n",
            "2020-01-07 09:38:41,626 Test: None\n",
            "Corpus: 115144 train + 12794 dev + 14215 test sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdHb4ySJ-E1E",
        "colab_type": "text"
      },
      "source": [
        "Input corpus is split into train(115144), dev(12794) and test(14215) sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyKDhvY9R6lt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2d22327-d416-453d-d6bf-8b902da7701f"
      },
      "source": [
        "tag_type = 'pos'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary.idx2item)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'<unk>', b'O', b'NNP', b'VBZ', b'VBN', b'DT', b'JJ', b'CC', b'NN', b'IN', b',', b'.', b'RB', b'PRP', b'NNS', b'PRP$', b'LRB', b'CD', b'RRB', b'VBG', b'TO', b'WDT', b'VBD', b':', b'NNPS', b'POS', b'VBP', b'LQU', b'VB', b'MD', b';', b'RP', b'RBR', b'WP', b'RQU', b'JJR', b'WP$', b'WRB', b'PDT', b'EX', b'RBS', b'JJS', b'AS', b'#', b'FW', b'$', b'UH', b'SO', b'SYM', b'LS', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68TF02qY-ZnM",
        "colab_type": "text"
      },
      "source": [
        "In total the dataset is tagged with 52 POS Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEb7x7zdVy7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a8e6eadb-6ec5-44d8-ea9f-7fe6b2a25984"
      },
      "source": [
        "embedding_types: List[TokenEmbeddings] = [\n",
        "     FlairEmbeddings('news-forward'),\n",
        "     FlairEmbeddings('news-backward'),\n",
        "]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:44:15,974 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpqbytw1bn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:08<00:00, 8433465.93B/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:44:25,767 copying /tmp/tmpqbytw1bn to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:44:25,861 removing temp file /tmp/tmpqbytw1bn\n",
            "2020-01-07 09:44:37,560 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmp2oyqlr3_\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034575/73034575 [00:08<00:00, 8165219.55B/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:44:47,645 copying /tmp/tmp2oyqlr3_ to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:44:47,737 removing temp file /tmp/tmp2oyqlr3_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRaRHVVY4wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sQVkBaAZLSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0GrKTuQZMTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOx9lZEmZNoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ade723d2-32f4-4f5a-8bbe-3d703f291206"
      },
      "source": [
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 09:45:19,751 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:19,754 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 256, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=52, bias=True)\n",
            ")\"\n",
            "2020-01-07 09:45:19,756 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:19,758 Corpus: \"Corpus: 115144 train + 12794 dev + 14215 test sentences\"\n",
            "2020-01-07 09:45:19,760 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:19,771 Parameters:\n",
            "2020-01-07 09:45:19,773  - learning_rate: \"0.1\"\n",
            "2020-01-07 09:45:19,776  - mini_batch_size: \"32\"\n",
            "2020-01-07 09:45:19,778  - patience: \"3\"\n",
            "2020-01-07 09:45:19,780  - anneal_factor: \"0.5\"\n",
            "2020-01-07 09:45:19,781  - max_epochs: \"150\"\n",
            "2020-01-07 09:45:19,783  - shuffle: \"True\"\n",
            "2020-01-07 09:45:19,785  - train_with_dev: \"False\"\n",
            "2020-01-07 09:45:19,786 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:19,788 Model training base path: \"resources/taggers/example-ner\"\n",
            "2020-01-07 09:45:19,790 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:19,792 Device: cuda:0\n",
            "2020-01-07 09:45:19,794 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:19,796 Embeddings storage mode: cpu\n",
            "2020-01-07 09:45:19,798 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 09:45:20,920 epoch 1 - iter 0/3599 - loss 101.20606995 - samples/sec: 16061.82\n",
            "2020-01-07 09:48:24,071 epoch 1 - iter 359/3599 - loss 18.38157395 - samples/sec: 65.45\n",
            "2020-01-07 09:51:29,228 epoch 1 - iter 718/3599 - loss 12.54552305 - samples/sec: 64.56\n",
            "2020-01-07 09:54:34,216 epoch 1 - iter 1077/3599 - loss 10.22096556 - samples/sec: 64.62\n",
            "2020-01-07 09:57:44,990 epoch 1 - iter 1436/3599 - loss 8.94677655 - samples/sec: 62.61\n",
            "2020-01-07 10:00:50,321 epoch 1 - iter 1795/3599 - loss 8.09913317 - samples/sec: 64.56\n",
            "2020-01-07 10:03:56,385 epoch 1 - iter 2154/3599 - loss 7.48776917 - samples/sec: 64.42\n",
            "2020-01-07 10:06:59,372 epoch 1 - iter 2513/3599 - loss 7.02104256 - samples/sec: 65.37\n",
            "2020-01-07 10:10:05,115 epoch 1 - iter 2872/3599 - loss 6.66303430 - samples/sec: 64.29\n",
            "2020-01-07 10:13:13,910 epoch 1 - iter 3231/3599 - loss 6.36506521 - samples/sec: 63.30\n",
            "2020-01-07 10:16:20,145 epoch 1 - iter 3590/3599 - loss 6.12213199 - samples/sec: 64.09\n",
            "2020-01-07 10:16:24,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 10:16:24,178 EPOCH 1 done: loss 6.1172 - lr 0.1000\n",
            "2020-01-07 10:20:26,580 DEV : loss 2.2083990573883057 - score 0.9704\n",
            "2020-01-07 10:20:36,760 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 10:20:37,231 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 10:20:38,819 epoch 2 - iter 0/3599 - loss 3.92844296 - samples/sec: 24713.02\n",
            "2020-01-07 10:23:45,093 epoch 2 - iter 359/3599 - loss 3.70915679 - samples/sec: 64.00\n",
            "2020-01-07 10:26:52,353 epoch 2 - iter 718/3599 - loss 3.69708515 - samples/sec: 64.02\n",
            "2020-01-07 10:29:58,853 epoch 2 - iter 1077/3599 - loss 3.66007391 - samples/sec: 64.06\n",
            "2020-01-07 10:33:04,451 epoch 2 - iter 1436/3599 - loss 3.61489447 - samples/sec: 64.39\n",
            "2020-01-07 10:36:10,239 epoch 2 - iter 1795/3599 - loss 3.59747536 - samples/sec: 64.21\n",
            "2020-01-07 10:39:16,614 epoch 2 - iter 2154/3599 - loss 3.55305630 - samples/sec: 64.02\n",
            "2020-01-07 10:42:21,628 epoch 2 - iter 2513/3599 - loss 3.52778156 - samples/sec: 64.53\n",
            "2020-01-07 10:45:27,853 epoch 2 - iter 2872/3599 - loss 3.50918568 - samples/sec: 64.14\n",
            "2020-01-07 10:48:33,819 epoch 2 - iter 3231/3599 - loss 3.49426832 - samples/sec: 64.30\n",
            "2020-01-07 10:51:38,767 epoch 2 - iter 3590/3599 - loss 3.47324620 - samples/sec: 64.59\n",
            "2020-01-07 10:51:42,628 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 10:51:42,630 EPOCH 2 done: loss 3.4727 - lr 0.1000\n",
            "2020-01-07 10:55:42,397 DEV : loss 1.942564845085144 - score 0.9729\n",
            "2020-01-07 10:55:52,536 BAD EPOCHS (no improvement): 0\n",
            "2020-01-07 10:55:52,989 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 10:55:53,996 epoch 3 - iter 0/3599 - loss 3.74628258 - samples/sec: 20479.39\n",
            "2020-01-07 10:59:00,278 epoch 3 - iter 359/3599 - loss 3.22136572 - samples/sec: 64.14\n",
            "2020-01-07 11:02:05,377 epoch 3 - iter 718/3599 - loss 3.22020577 - samples/sec: 64.58\n",
            "2020-01-07 11:05:11,922 epoch 3 - iter 1077/3599 - loss 3.20518928 - samples/sec: 64.08\n",
            "2020-01-07 11:08:17,467 epoch 3 - iter 1436/3599 - loss 3.17511479 - samples/sec: 64.43\n",
            "2020-01-07 11:11:26,850 epoch 3 - iter 1795/3599 - loss 3.16151444 - samples/sec: 63.10\n",
            "2020-01-07 11:14:30,256 epoch 3 - iter 2154/3599 - loss 3.13414520 - samples/sec: 65.34\n",
            "2020-01-07 11:17:29,884 epoch 3 - iter 2513/3599 - loss 3.11997779 - samples/sec: 66.70\n",
            "2020-01-07 11:20:34,962 epoch 3 - iter 2872/3599 - loss 3.11666212 - samples/sec: 64.61\n",
            "2020-01-07 11:23:34,513 epoch 3 - iter 3231/3599 - loss 3.10232248 - samples/sec: 66.60\n",
            "2020-01-07 11:26:34,100 epoch 3 - iter 3590/3599 - loss 3.09383469 - samples/sec: 66.67\n",
            "2020-01-07 11:26:37,670 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 11:26:37,672 EPOCH 3 done: loss 3.0919 - lr 0.1000\n",
            "2020-01-07 11:30:31,507 DEV : loss 1.8504215478897095 - score 0.9742\n",
            "2020-01-07 11:30:41,594 BAD EPOCHS (no improvement): 0\n",
            "2020-01-07 11:30:42,057 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 11:30:43,080 epoch 4 - iter 0/3599 - loss 5.19068527 - samples/sec: 19123.99\n",
            "2020-01-07 11:33:45,649 epoch 4 - iter 359/3599 - loss 3.06102347 - samples/sec: 65.37\n",
            "2020-01-07 11:36:47,854 epoch 4 - iter 718/3599 - loss 3.01533899 - samples/sec: 65.54\n",
            "2020-01-07 11:39:46,768 epoch 4 - iter 1077/3599 - loss 2.96931317 - samples/sec: 66.82\n",
            "2020-01-07 11:42:49,401 epoch 4 - iter 1436/3599 - loss 2.95121931 - samples/sec: 65.31\n",
            "2020-01-07 11:45:51,092 epoch 4 - iter 1795/3599 - loss 2.94326551 - samples/sec: 65.92\n",
            "2020-01-07 11:48:54,696 epoch 4 - iter 2154/3599 - loss 2.93806516 - samples/sec: 65.11\n",
            "2020-01-07 11:51:53,966 epoch 4 - iter 2513/3599 - loss 2.92261195 - samples/sec: 66.73\n",
            "2020-01-07 11:54:55,082 epoch 4 - iter 2872/3599 - loss 2.91502147 - samples/sec: 66.05\n",
            "2020-01-07 11:57:59,074 epoch 4 - iter 3231/3599 - loss 2.90648234 - samples/sec: 64.87\n",
            "2020-01-07 12:01:02,844 epoch 4 - iter 3590/3599 - loss 2.90399483 - samples/sec: 65.18\n",
            "2020-01-07 12:01:07,324 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 12:01:07,325 EPOCH 4 done: loss 2.9034 - lr 0.1000\n",
            "2020-01-07 12:05:04,015 DEV : loss 1.758891224861145 - score 0.9749\n",
            "2020-01-07 12:05:14,239 BAD EPOCHS (no improvement): 0\n",
            "2020-01-07 12:05:14,681 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 12:05:15,653 epoch 5 - iter 0/3599 - loss 2.13938570 - samples/sec: 17061.99\n",
            "2020-01-07 12:08:19,534 epoch 5 - iter 359/3599 - loss 2.80582663 - samples/sec: 65.12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-50:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:11:33,549 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 12:11:33,551 Exiting from training early.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:11:33,555 Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7efd4bb563c8>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "KeyboardInterrupt: \n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:11:34,014 Done.\n",
            "2020-01-07 12:11:34,019 ----------------------------------------------------------------------------------------------------\n",
            "2020-01-07 12:11:34,022 Testing using best model ...\n",
            "2020-01-07 12:11:34,027 loading file resources/taggers/example-ner/best-model.pt\n",
            "2020-01-07 12:15:32,686 0.9753\t0.9753\t0.9753\n",
            "2020-01-07 12:15:32,688 \n",
            "MICRO_AVG: acc 0.9518 - f1-score 0.9753\n",
            "MACRO_AVG: acc 0.8645 - f1-score 0.9041106382978724\n",
            "#          tp: 27 - fp: 1 - fn: 3 - tn: 27 - precision: 0.9643 - recall: 0.9000 - accuracy: 0.8710 - f1-score: 0.9310\n",
            "$          tp: 126 - fp: 8 - fn: 0 - tn: 126 - precision: 0.9403 - recall: 1.0000 - accuracy: 0.9403 - f1-score: 0.9692\n",
            ",          tp: 18314 - fp: 0 - fn: 0 - tn: 18314 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            ".          tp: 13982 - fp: 0 - fn: 0 - tn: 13982 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            ":          tp: 749 - fp: 95 - fn: 25 - tn: 749 - precision: 0.8874 - recall: 0.9677 - accuracy: 0.8619 - f1-score: 0.9258\n",
            ";          tp: 541 - fp: 0 - fn: 0 - tn: 541 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "AS         tp: 3 - fp: 1 - fn: 1 - tn: 3 - precision: 0.7500 - recall: 0.7500 - accuracy: 0.6000 - f1-score: 0.7500\n",
            "CC         tp: 10422 - fp: 12 - fn: 24 - tn: 10422 - precision: 0.9988 - recall: 0.9977 - accuracy: 0.9966 - f1-score: 0.9982\n",
            "CD         tp: 9980 - fp: 111 - fn: 148 - tn: 9980 - precision: 0.9890 - recall: 0.9854 - accuracy: 0.9747 - f1-score: 0.9872\n",
            "DT         tp: 34194 - fp: 36 - fn: 76 - tn: 34194 - precision: 0.9989 - recall: 0.9978 - accuracy: 0.9967 - f1-score: 0.9983\n",
            "EX         tp: 324 - fp: 7 - fn: 9 - tn: 324 - precision: 0.9789 - recall: 0.9730 - accuracy: 0.9529 - f1-score: 0.9759\n",
            "FW         tp: 62 - fp: 24 - fn: 85 - tn: 62 - precision: 0.7209 - recall: 0.4218 - accuracy: 0.3626 - f1-score: 0.5322\n",
            "IN         tp: 43667 - fp: 253 - fn: 231 - tn: 43667 - precision: 0.9942 - recall: 0.9947 - accuracy: 0.9890 - f1-score: 0.9944\n",
            "JJ         tp: 21841 - fp: 1494 - fn: 1737 - tn: 21841 - precision: 0.9360 - recall: 0.9263 - accuracy: 0.8711 - f1-score: 0.9311\n",
            "JJR        tp: 619 - fp: 59 - fn: 81 - tn: 619 - precision: 0.9130 - recall: 0.8843 - accuracy: 0.8155 - f1-score: 0.8984\n",
            "JJS        tp: 818 - fp: 47 - fn: 49 - tn: 818 - precision: 0.9457 - recall: 0.9435 - accuracy: 0.8950 - f1-score: 0.9446\n",
            "LQU        tp: 1630 - fp: 6 - fn: 8 - tn: 1630 - precision: 0.9963 - recall: 0.9951 - accuracy: 0.9915 - f1-score: 0.9957\n",
            "LRB        tp: 2203 - fp: 3 - fn: 0 - tn: 2203 - precision: 0.9986 - recall: 1.0000 - accuracy: 0.9986 - f1-score: 0.9993\n",
            "MD         tp: 1267 - fp: 3 - fn: 6 - tn: 1267 - precision: 0.9976 - recall: 0.9953 - accuracy: 0.9929 - f1-score: 0.9964\n",
            "NN         tp: 43647 - fp: 1313 - fn: 2134 - tn: 43647 - precision: 0.9708 - recall: 0.9534 - accuracy: 0.9268 - f1-score: 0.9620\n",
            "NNP        tp: 41733 - fp: 1903 - fn: 1015 - tn: 41733 - precision: 0.9564 - recall: 0.9763 - accuracy: 0.9346 - f1-score: 0.9662\n",
            "NNPS       tp: 721 - fp: 273 - fn: 225 - tn: 721 - precision: 0.7254 - recall: 0.7622 - accuracy: 0.5915 - f1-score: 0.7433\n",
            "NNS        tp: 17406 - fp: 556 - fn: 502 - tn: 17406 - precision: 0.9690 - recall: 0.9720 - accuracy: 0.9427 - f1-score: 0.9705\n",
            "PDT        tp: 62 - fp: 14 - fn: 4 - tn: 62 - precision: 0.8158 - recall: 0.9394 - accuracy: 0.7750 - f1-score: 0.8732\n",
            "POS        tp: 2996 - fp: 10 - fn: 2 - tn: 2996 - precision: 0.9967 - recall: 0.9993 - accuracy: 0.9960 - f1-score: 0.9980\n",
            "PRP        tp: 4792 - fp: 21 - fn: 19 - tn: 4792 - precision: 0.9956 - recall: 0.9961 - accuracy: 0.9917 - f1-score: 0.9958\n",
            "PRP$       tp: 3900 - fp: 16 - fn: 9 - tn: 3900 - precision: 0.9959 - recall: 0.9977 - accuracy: 0.9936 - f1-score: 0.9968\n",
            "RB         tp: 9796 - fp: 262 - fn: 362 - tn: 9796 - precision: 0.9740 - recall: 0.9644 - accuracy: 0.9401 - f1-score: 0.9692\n",
            "RBR        tp: 242 - fp: 62 - fn: 63 - tn: 242 - precision: 0.7961 - recall: 0.7934 - accuracy: 0.6594 - f1-score: 0.7947\n",
            "RBS        tp: 325 - fp: 21 - fn: 21 - tn: 325 - precision: 0.9393 - recall: 0.9393 - accuracy: 0.8856 - f1-score: 0.9393\n",
            "RP         tp: 480 - fp: 60 - fn: 31 - tn: 480 - precision: 0.8889 - recall: 0.9393 - accuracy: 0.8406 - f1-score: 0.9134\n",
            "RQU        tp: 1469 - fp: 0 - fn: 5 - tn: 1469 - precision: 1.0000 - recall: 0.9966 - accuracy: 0.9966 - f1-score: 0.9983\n",
            "RRB        tp: 2208 - fp: 0 - fn: 0 - tn: 2208 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "SO         tp: 32 - fp: 19 - fn: 11 - tn: 32 - precision: 0.6275 - recall: 0.7442 - accuracy: 0.5161 - f1-score: 0.6809\n",
            "SYM        tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "TO         tp: 7058 - fp: 9 - fn: 2 - tn: 7058 - precision: 0.9987 - recall: 0.9997 - accuracy: 0.9984 - f1-score: 0.9992\n",
            "UH         tp: 1 - fp: 1 - fn: 10 - tn: 1 - precision: 0.5000 - recall: 0.0909 - accuracy: 0.0833 - f1-score: 0.1538\n",
            "VB         tp: 5266 - fp: 169 - fn: 282 - tn: 5266 - precision: 0.9689 - recall: 0.9492 - accuracy: 0.9211 - f1-score: 0.9589\n",
            "VBD        tp: 14131 - fp: 366 - fn: 524 - tn: 14131 - precision: 0.9748 - recall: 0.9642 - accuracy: 0.9407 - f1-score: 0.9695\n",
            "VBG        tp: 4545 - fp: 264 - fn: 209 - tn: 4545 - precision: 0.9451 - recall: 0.9560 - accuracy: 0.9057 - f1-score: 0.9505\n",
            "VBN        tp: 9182 - fp: 805 - fn: 434 - tn: 9182 - precision: 0.9194 - recall: 0.9549 - accuracy: 0.8811 - f1-score: 0.9368\n",
            "VBP        tp: 2450 - fp: 170 - fn: 109 - tn: 2450 - precision: 0.9351 - recall: 0.9574 - accuracy: 0.8978 - f1-score: 0.9461\n",
            "VBZ        tp: 5620 - fp: 135 - fn: 166 - tn: 5620 - precision: 0.9765 - recall: 0.9713 - accuracy: 0.9492 - f1-score: 0.9739\n",
            "WDT        tp: 1547 - fp: 36 - fn: 26 - tn: 1547 - precision: 0.9773 - recall: 0.9835 - accuracy: 0.9615 - f1-score: 0.9804\n",
            "WP         tp: 801 - fp: 0 - fn: 2 - tn: 801 - precision: 1.0000 - recall: 0.9975 - accuracy: 0.9975 - f1-score: 0.9987\n",
            "WP$        tp: 48 - fp: 0 - fn: 0 - tn: 48 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "WRB        tp: 777 - fp: 6 - fn: 0 - tn: 777 - precision: 0.9923 - recall: 1.0000 - accuracy: 0.9923 - f1-score: 0.9961\n",
            "2020-01-07 12:15:32,695 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(2.2084, device='cuda:0'),\n",
              "  tensor(1.9426, device='cuda:0'),\n",
              "  tensor(1.8504, device='cuda:0'),\n",
              "  tensor(1.7589, device='cuda:0')],\n",
              " 'dev_score_history': [0.9704, 0.9729, 0.9742, 0.9749],\n",
              " 'test_score': 0.9753,\n",
              " 'train_loss_history': [6.1171543689263,\n",
              "  3.4727155129821408,\n",
              "  3.091912110966754,\n",
              "  2.903443764533954]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZqvizp7-r3_",
        "colab_type": "text"
      },
      "source": [
        "Fetching best model after 3 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Coio0FZPAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32c5b015-f7c5-424b-86e7-140367af5989"
      },
      "source": [
        "model = SequenceTagger.load('resources/taggers/example-ner/best-model.pt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-07 12:15:49,592 loading file resources/taggers/example-ner/best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-eK_pam-wd7",
        "colab_type": "text"
      },
      "source": [
        "Run prediction on random sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4gxwxja6Hj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "76645300-da38-43f0-a961-acb188630e42"
      },
      "source": [
        "sentence = Sentence('type iv securities. a national bank may purchase and sell type iv securities for its own account. the amount of the type iv securities that a bank may purchase and sell is not limited to a specified percentage of the banks capital and surplus.')\n",
        "model.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type <NN> iv <NN> securities. <NN> a <DT> national <JJ> bank <NN> may <MD> purchase <VB> and <CC> sell <VB> type <NN> iv <NN> securities <NNS> for <IN> its <PRP$> own <JJ> account. <NN> the <DT> amount <NN> of <IN> the <DT> type <NN> iv <NN> securities <NNS> that <IN> a <DT> bank <NN> may <MD> purchase <VB> and <CC> sell <VB> is <VBZ> not <RB> limited <VBN> to <TO> a <DT> specified <JJ> percentage <NN> of <IN> the <DT> banks <NNS> capital <NN> and <CC> surplus. <NN>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}